## The Form Paradox
Fónagy (1961) noted that rhythmical and phonic organization of poetry should, it
seems, decrease unpredictability and entropy, contrary to his experimental results. In  the same collection where that article was published, we find a short, but insightful, article by Abernathy (1961) where the same idea is put in this striking way: “poetry uses a considerably circumscribed and impoverished language compared to the everyday speech.” Abernathy proposed to resolve this paradox by ascribing a subjective probability to each message and postulating that poems are characterized by a drastically lower probability, i.e., higher unexpectedness, despite the fact
that they use “a considerably circumscribed” language. Unfortunately, this is a
rather nonconstructive approach, since it is not clear how to ascribe probabilities
to texts, and, more importantly, why or whether lower probability would result from
satisfying formal restrictions.

A much more detailed exploration of this paradox is due to A.N. Kolmogorov, a
great mathematician with a deep interest in literature. In a series of unpublished (at
the time) works popularized by Lotman (1977) (see also Kolmogorov, 1997; Yaglom
and Yaglom, 1983), he was developing a formalized approach based on considering
a set of all possible texts and a particular poem as a member of this set. A poet can
be seen as selecting or finding the text that expresses the desired meaning and at the
same time satisfies some formal constraints.  As an illustration, consider the set of all character sequences, say, no longer than War and Peace. It is a very large, but finite, number. There would be in this set a small subset of grammatically correct and meaningful Russian texts. In this highly idealized model, we don’t care what exactly the “meaning” is, but we postulate that each character sequence has either no meaning or exactly one, and that given any two “meanings” we can always say whether they are the same or different. Subdivide all texts into equivalence classes by synonymy, so that each class contains texts that all mean the same. In other words, each class would express in all possible ways
some content different from that of the other classes. Consider the synonymy class
in which all texts express the meaning of, say, Eugene Onegin. If this class is large
enough, one can find in it a text that is composed in Onegin stanzas, which is what
a poet does. Then the number of synonymy classes would be equal to the number of meanings expressible with texts no longer than War and Peace, and the average number of
texts in each class is essentially the number of different ways to express any given
meaning. According to Kolmogorov, the former quantity (or rather, its logarithm)
reflects the “content capacity entropy” of the language (h1 ), while the latter one
reflects its “flexibility entropy” (h2 ). If the flexibility entropy is large enough, i.e.,
if the given content can be expressed in a large enough number of ways, one can expect to find among those ways some that also satisfy the formal restrictions of
versification. Because formal constraints reduce the pool of admissible texts, they
can be characterized by a negative entropy (β), and Kolmogorov proposed that
versification is only possible in languages where β < h2 . Of course, one can’t get rid of the feeling that something is wrong in this picture.  Cf. the uncharacteristically impressionistic passage in a classical text on probability and information (Yaglom and Yaglom, 1983, p. 214):
However, in the compositions of many eminent poets the decrease in the information content of one text letter, related to the fulfilment of known formal rules, is apparently compensated for to a great extent by the enhanced radiance and unconventionality of language. Therefore, it can be well expected that here the redundancy of the language has the same order as that of a prose literary text.  I suppose Kolmogorov felt that way too, which is why he apparently never published his model. In fact, in an undated manuscript (Kolmogorov, 2002) first published by Uspensky (2002), he wrote: “Poetry admits somewhat freer use of word order unconventional in prose, which somewhat increases [the flexibility entropy].” This essentially means that the basic notion of the set of all admissible
texts is somewhat fuzzy: what is barely admissible in prose can be quite admissible
in poetry. But if the statistical population is not well defined, probability and,
hence, information are also ill-defined. One can even surmise that it was this train
of thought that eventually led Kolmogorov to propose his algorithmic complexity
theory. There is a telling remark in his groundbreaking paper (Kolmogorov, 1968)
after the introduction of what is now known as Kolmogorov complexity: “such
quantities as the ‘complexity’ of the text of ‘War and Peace’ can be assumed to
be defined with what amounts to uniqueness.”  Uspensky in his preface to the publication of Kolmogorov’s notes (Uspensky, 1997) also admits that “the very notion that the corpus of literary texts is only a subset of the corpus of meaningful texts” requires rethinking and gives an example of the famous nonsense line from a poem by the Russian modernist
poet Kruchenykh, consisting of three meaningless monosyllabics “Dyr bul shchyl”
(Perloff, 2017, p. 73). Note, however, that while Kolmogorov pointed out the
relaxation of syntactic norms in poetry, Uspensky’s example hints at the possible
relaxation of semantic norms. In fact, such relaxation is well-known to literary scholars. We are used to the notion of metaphor as a specific feature of poetry and literary prose, but most  metaphors are literally absurd phrases, inadmissible by the standard semantics of
the language, as one can see with any textbook example like “the curtain of the
night fell upon us” or “Juliet is the sun.” So it’s easy to see that metaphor (as well as
metonymy and other tropes) already serves to expand the space of admissible texts
in the semantic dimension. \

As for syntactic expansion, an obvious example is the word order violation often arising from the demands of poetic form. However, not all syntactic oddities arise for purely technical reasons. Many figures of speech known and meticulously catalogued at least since antiquity are particular ways to enhance expression by violating rules of syntax. Consider, for example, the opening of G.M. Hopkins’1006 D. Manin
poem “To His Watch”: “Mortal my mate. . . ” (Hopkins and Blaisdell, 2013, p. 84).
From the point of view of rhythm, the standard word order, “My mortal mate,”
wouldn’t be any inferior, but Hopkins forcefully emphasizes mortality, the theme of
the poem, by shifting the word to the syntactically awkward initial position.
To summarize, it appears that although poetic form does narrow down the
statistical population of all admissible texts, various poetic devices counteract
by expanding it and by pushing the boundaries of the standard language syntax
and semantics. In this way, they keep the language of poetry from becoming
“considerably circumscribed and impoverished” (Abernathy, 1961) and prevent entropy reduction
